{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "from nltk import classify\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model loading\n",
    "I will be using the Logistic Regression Classifier since it's the most accurate (87.9%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model with pickle\n",
    "LRClassifier = \"..\\\\Models\\\\LRClassifier.pkl\"\n",
    "with open(LRClassifier, 'rb') as file:\n",
    "    LRClassifier = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing tweets from April\n",
    "tweets = pd.read_csv('..\\\\Datasets\\\\JSON\\\\April\\\\dataCleaned.csv', usecols=[\n",
    "    'data', 'text', 'date'], engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "* Tokenization\n",
    "* Stemmatization\n",
    "* Removal of italian stopwords\n",
    "* Removal of punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Italian stopwords\n",
    "stop_words = stopwords.words('italian')\n",
    "\n",
    "# Italian Stemmer\n",
    "stemmer = SnowballStemmer('italian')\n",
    "\n",
    "\n",
    "# Additional stopwords found online\n",
    "def additional_stop_words():\n",
    "    with open('Training\\\\stopwords.txt', 'r') as f:\n",
    "        additional_stopwords = f.readlines()\n",
    "    additional_stopwords = [x.strip() for x in additional_stopwords]\n",
    "    return additional_stopwords\n",
    "\n",
    "\n",
    "# Function to remove noise from tokens, removing also stopwords\n",
    "def remove_noise(tweet_tokens, stop_words=(), additional_stop_words=()):\n",
    "    cleaned_tokens = []\n",
    "    for token in tweet_tokens:\n",
    "        token = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\n",
    "                       '(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', token)\n",
    "        token = re.sub(\"(@[A-Za-z0-9_]+)\", \"\", token)\n",
    "        token = stemmer.stem(token)\n",
    "        if len(token) > 1 and token not in string.punctuation and token.lower() not in stop_words and token.lower() not in additional_stop_words:\n",
    "            cleaned_tokens.append(token.lower())\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding tweets and tokenized from april to list\n",
    "april = tweets.data.values.tolist()\n",
    "tokenized = tweets.text.values.tolist()\n",
    "date = tweets.date.values.tolist()\n",
    "# List of classified tweets from april\n",
    "classified = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each tweet, remove noise and tokenize, calculate the accuracy of a given prediction\n",
    "# and add to classified list\n",
    "for tweet in april:\n",
    "    custom_tokens = remove_noise(word_tokenize(tweet))\n",
    "    classified.append(tuple((tweet, LRClassifier.prob_classify(\n",
    "        dict([token, True] for token in custom_tokens)).prob('Positive'), LRClassifier.prob_classify(\n",
    "        dict([token, True] for token in custom_tokens)).prob('Negative'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe from classified tweets\n",
    "df = pd.DataFrame(classified, columns=['tweet', 'positive', 'negative'])\n",
    "\n",
    "# Obtain polarity by subtracting positives with negatives values\n",
    "df['polarity'] = df['positive'] - df['negative']\n",
    "\n",
    "# Adding tokenized column\n",
    "df['tokenized'] = tokenized\n",
    "\n",
    "# Adding date column\n",
    "df['date'] = date\n",
    "\n",
    "# Reordering columns\n",
    "df = df[['date', 'tweet', 'tokenized', 'positive', 'negative', 'polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        date  \\\n",
      "0  2020-04-30 23:59:54+00:00   \n",
      "1  2020-04-30 23:59:34+00:00   \n",
      "2  2020-04-30 23:59:08+00:00   \n",
      "3  2020-04-30 23:58:44+00:00   \n",
      "4  2020-04-30 23:58:19+00:00   \n",
      "5  2020-04-30 23:57:01+00:00   \n",
      "6  2020-04-30 23:56:23+00:00   \n",
      "7  2020-04-30 23:56:13+00:00   \n",
      "8  2020-04-30 23:55:06+00:00   \n",
      "9  2020-04-30 23:54:53+00:00   \n",
      "\n",
      "                                               tweet  \\\n",
      "0  Usa si fermano allevamentiintensivi e impianti...   \n",
      "1  Coronavirus Speranza firma decreto criteri mon...   \n",
      "2  La Lega occupa il Parlamento a rischio Coronav...   \n",
      "3  gb boris johnson ampquotSuperato il picco di e...   \n",
      "4  Coronavirus il bilancio del 30 aprile record d...   \n",
      "5  Coronavirus pi di 230mila morti nel mondo Posi...   \n",
      "6  COVID19 Esiste una teoria piuttosto seria seco...   \n",
      "7  Secondo tito boeri da cui ilsole24ore ha ripre...   \n",
      "8  La Lega occupa il Parlamento a rischio Coronav...   \n",
      "9  Coronavirus dagli assembramenti agli orari di ...   \n",
      "\n",
      "                                           tokenized  positive  negative  \\\n",
      "0  usa fermano allevamentiintensivi impianti lavo...  0.849461  0.150539   \n",
      "1  coronavirus speranza firma decreto criteri mon...  0.388083  0.611917   \n",
      "2  lega occupa parlamento rischio coronavirus via...  0.340140  0.659860   \n",
      "3  gb boris johnson ampquotsuperato picco epidemi...  0.768763  0.231237   \n",
      "4  coronavirus bilancio 30 aprile record guariti ...  0.014200  0.985800   \n",
      "5  coronavirus pi 230mila morti mondo positivo pr...  0.107946  0.892054   \n",
      "6  covid19 esiste teoria piuttosto seria secondo ...  0.471560  0.528440   \n",
      "7  secondo tito boeri ilsole24ore ripreso relazio...  0.672890  0.327110   \n",
      "8  lega occupa parlamento rischio coronavirus via...  0.332157  0.667843   \n",
      "9  coronavirus assembramenti orari punta fino con...  0.646094  0.353906   \n",
      "\n",
      "   polarity  \n",
      "0  0.698922  \n",
      "1 -0.223834  \n",
      "2 -0.319719  \n",
      "3  0.537526  \n",
      "4 -0.971600  \n",
      "5 -0.784109  \n",
      "6 -0.056880  \n",
      "7  0.345780  \n",
      "8 -0.335687  \n",
      "9  0.292189  \n"
     ]
    }
   ],
   "source": [
    "# Quick glance at the dataframe\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving dataframe to csv\n",
    "df.to_csv('..\\\\Datasets\\\\CSV\\\\april_analyzed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "from nltk import classify\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model loading\n",
    "I will be using the Logistic Regression Classifier since it's the most accurate (87.9%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model with pickle\n",
    "LRClassifier = \"..\\\\Models\\\\LRClassifier.pkl\"\n",
    "with open(LRClassifier, 'rb') as file:\n",
    "    LRClassifier = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing tweets from March\n",
    "march_tweets = pd.read_csv('..\\\\Datasets\\\\JSON\\\\March\\\\dataCleaned.csv', usecols=[\n",
    "    'data', 'text', 'date'], engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "* Tokenization\n",
    "* Stemmatization\n",
    "* Removal of italian stopwords\n",
    "* Removal of punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Italian stopwords\n",
    "stop_words = stopwords.words('italian')\n",
    "\n",
    "# Italian Stemmer\n",
    "stemmer = SnowballStemmer('italian')\n",
    "\n",
    "\n",
    "# Additional stopwords found online\n",
    "def additional_stop_words():\n",
    "    with open('Training\\\\stopwords.txt', 'r') as f:\n",
    "        additional_stopwords = f.readlines()\n",
    "    additional_stopwords = [x.strip() for x in additional_stopwords]\n",
    "    return additional_stopwords\n",
    "\n",
    "\n",
    "# Function to remove noise from tokens, removing also stopwords\n",
    "def remove_noise(tweet_tokens, stop_words=(), additional_stop_words=()):\n",
    "    cleaned_tokens = []\n",
    "    for token in tweet_tokens:\n",
    "        token = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\n",
    "                       '(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', token)\n",
    "        token = re.sub(\"(@[A-Za-z0-9_]+)\", \"\", token)\n",
    "        token = stemmer.stem(token)\n",
    "        if len(token) > 1 and token not in string.punctuation and token.lower() not in stop_words and token.lower() not in additional_stop_words:\n",
    "            cleaned_tokens.append(token.lower())\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding tweets and tokenized from march to list\n",
    "march = march_tweets.data.values.tolist()\n",
    "tokenized = march_tweets.text.values.tolist()\n",
    "date = march_tweets.date.values.tolist()\n",
    "# List of classified tweets from march\n",
    "classified = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each tweet, remove noise and tokenize, calculate the accuracy of a given prediction\n",
    "# and add to classified list\n",
    "for tweet in march:\n",
    "    custom_tokens = remove_noise(word_tokenize(tweet))\n",
    "    classified.append(tuple((tweet, LRClassifier.prob_classify(\n",
    "        dict([token, True] for token in custom_tokens)).prob('Positive'), LRClassifier.prob_classify(\n",
    "        dict([token, True] for token in custom_tokens)).prob('Negative'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe from classified tweets\n",
    "df = pd.DataFrame(classified, columns=['tweet', 'positive', 'negative'])\n",
    "\n",
    "# Obtain polarity by subtracting positives with negatives values\n",
    "df['polarity'] = df['positive'] - df['negative']\n",
    "\n",
    "# Adding tokenized column\n",
    "df['tokenized'] = tokenized\n",
    "\n",
    "# Adding date column\n",
    "df['date'] = date\n",
    "\n",
    "# Reordering columns\n",
    "df = df[['date', 'tweet', 'tokenized', 'positive', 'negative', 'polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        date  \\\n",
      "0  2020-03-01 23:59:55+00:00   \n",
      "1  2020-03-01 23:59:54+00:00   \n",
      "2  2020-03-01 23:59:54+00:00   \n",
      "3  2020-03-01 23:59:35+00:00   \n",
      "4  2020-03-01 23:59:31+00:00   \n",
      "5  2020-03-01 23:59:15+00:00   \n",
      "6  2020-03-01 23:58:40+00:00   \n",
      "7  2020-03-01 23:58:26+00:00   \n",
      "8  2020-03-01 23:58:05+00:00   \n",
      "9  2020-03-01 23:57:47+00:00   \n",
      "\n",
      "                                               tweet  \\\n",
      "0  Cazzarola ora tutto pi chiaro Altro che cinesi...   \n",
      "1  566 nuovi casi dallinizio di domenicalive none...   \n",
      "2  coronavirus scuole conte campania ULTIMISSIMA ...   \n",
      "3  Il commento di HoaraBorselli contro AdrianoPan...   \n",
      "4  MotoGP 2020 Coronavirus Cancellati i primi due...   \n",
      "5  amore ai tempi del corona virus mia figlia mi ...   \n",
      "6  Ho messo un aggregato dei dati disponibili su ...   \n",
      "7  Ecco le istruzioni per creare il vaccino del c...   \n",
      "8                           Coronavirus buone regole   \n",
      "9  VIDEO Il Coronavirus monopolizza l informazion...   \n",
      "\n",
      "                                           tokenized  positive  negative  \\\n",
      "0  cazzarola ora pi chiaro altro cinesi coronavir...  0.609563  0.390437   \n",
      "1  566 nuovi casi dallinizio domenicalive nonelad...  0.547676  0.452324   \n",
      "2  coronavirus scuole conte campania ultimissima ...  0.153650  0.846350   \n",
      "3  commento hoaraborselli adrianopanzironi nonela...  0.379965  0.620035   \n",
      "4  motogp 2020 coronavirus cancellati primi due g...  0.430066  0.569934   \n",
      "5  amore tempi corona virus figlia aspettava irga...  0.859512  0.140488   \n",
      "6  messo aggregato dati disponibili coronavirus r...  0.423503  0.576497   \n",
      "7  ecco istruzioni creare vaccino coronavirus div...  0.553927  0.446073   \n",
      "8                           coronavirus buone regole  0.883925  0.116075   \n",
      "9  video coronavirus monopolizza informazione vuo...  0.222161  0.777839   \n",
      "\n",
      "   polarity  \n",
      "0  0.219127  \n",
      "1  0.095351  \n",
      "2 -0.692701  \n",
      "3 -0.240070  \n",
      "4 -0.139867  \n",
      "5  0.719025  \n",
      "6 -0.152994  \n",
      "7  0.107853  \n",
      "8  0.767851  \n",
      "9 -0.555678  \n"
     ]
    }
   ],
   "source": [
    "# Quick glance at the dataframe\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving dataframe to csv\n",
    "df.to_csv('..\\\\Datasets\\\\CSV\\\\april_analyzed.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

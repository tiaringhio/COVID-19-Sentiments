{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "from nltk import classify\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model loading\n",
    "I will be using the Logistic Regression Classifier since it's the most accurate and most consistent (88%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model with pickle\n",
    "LRClassifier = \"..\\\\Models\\\\LRClassifier.pkl\"\n",
    "with open(LRClassifier, 'rb') as file:\n",
    "    LRClassifier = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing tweets from january\n",
    "tweets = pd.read_csv('..\\\\Datasets\\\\JSON\\\\January\\\\dataCleaned.csv', usecols=[\n",
    "    'data', 'text', 'date'], engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "* Tokenization\n",
    "* Stemmatization\n",
    "* Removal of italian stopwords\n",
    "* Removal of punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Italian stopwords\n",
    "stop_words = stopwords.words('italian')\n",
    "\n",
    "# Italian Stemmer\n",
    "stemmer = SnowballStemmer('italian')\n",
    "\n",
    "\n",
    "# Additional stopwords found online\n",
    "def additional_stop_words():\n",
    "    with open('Training\\\\stopwords.txt', 'r') as f:\n",
    "        additional_stopwords = f.readlines()\n",
    "    additional_stopwords = [x.strip() for x in additional_stopwords]\n",
    "    return additional_stopwords\n",
    "\n",
    "\n",
    "# Function to remove noise from tokens, removing also stopwords\n",
    "def remove_noise(tweet_tokens, stop_words=(), additional_stop_words=()):\n",
    "    cleaned_tokens = []\n",
    "    for token in tweet_tokens:\n",
    "        token = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\n",
    "                       '(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', token)\n",
    "        token = re.sub(\"(@[A-Za-z0-9_]+)\", \"\", token)\n",
    "        token = stemmer.stem(token)\n",
    "        if len(token) > 1 and token not in string.punctuation and token.lower() not in stop_words and token.lower() not in additional_stop_words:\n",
    "            cleaned_tokens.append(token.lower())\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding tweets and tokenized from january to list\n",
    "january = tweets.data.values.tolist()\n",
    "tokenized = tweets.text.values.tolist()\n",
    "date = tweets.date.values.tolist()\n",
    "# List of classified tweets from january\n",
    "classified = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each tweet, remove noise and tokenize, calculate the accuracy of a given prediction\n",
    "# and add to classified list\n",
    "for tweet in january:\n",
    "    custom_tokens = remove_noise(word_tokenize(tweet))\n",
    "    classified.append(tuple((tweet, LRClassifier.prob_classify(\n",
    "        dict([token, True] for token in custom_tokens)).prob('Positive'), LRClassifier.prob_classify(\n",
    "        dict([token, True] for token in custom_tokens)).prob('Negative'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe from classified tweets\n",
    "df = pd.DataFrame(classified, columns=['tweet', 'positive', 'negative'])\n",
    "\n",
    "# Obtain polarity by subtracting positives with negatives values\n",
    "df['polarity'] = df['positive'] - df['negative']\n",
    "\n",
    "# Adding tokenized column\n",
    "df['tokenized'] = tokenized\n",
    "\n",
    "# Adding date column\n",
    "df['date'] = date\n",
    "\n",
    "# Reordering columns\n",
    "df = df[['date', 'tweet', 'tokenized', 'positive', 'negative', 'polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        date  \\\n",
      "0  2020-01-30 23:59:55+00:00   \n",
      "1  2020-01-30 23:59:50+00:00   \n",
      "2  2020-01-30 23:59:49+00:00   \n",
      "3  2020-01-30 23:59:35+00:00   \n",
      "4  2020-01-30 23:59:25+00:00   \n",
      "5  2020-01-30 23:59:17+00:00   \n",
      "6  2020-01-30 23:59:12+00:00   \n",
      "7  2020-01-30 23:59:10+00:00   \n",
      "8  2020-01-30 23:59:05+00:00   \n",
      "9  2020-01-30 23:58:58+00:00   \n",
      "\n",
      "                                               tweet  \\\n",
      "0  piazzapulita Formigli lo posso dire Stasera st...   \n",
      "1  Due casi confermati in Italia una coppia di tu...   \n",
      "2  Anche stavolta azzecchiamo il trend topic doma...   \n",
      "3  Mannoni raccomanda di informarsi al meglio sul...   \n",
      "4  Coronavirus a Roma due turisti cinesi infetti ...   \n",
      "5  dovresti vedere la trasmissione ti scoppierebb...   \n",
      "6  GiuseppeConteIT noi Italiani non siamo stupidi...   \n",
      "7  Detto questo voglio ricordare che attualmente ...   \n",
      "8        sulla gestione della situazione coronavirus   \n",
      "9  Lineanotte niente allarmismi Salvo parlare da ...   \n",
      "\n",
      "                                           tokenized  positive  negative  \\\n",
      "0  piazzapulita formigli posso dire stasera stori...  0.773648  0.226352   \n",
      "1  due casi confermati italia coppia turisti cine...  0.136872  0.863128   \n",
      "2  stavolta azzecchiamo trend topic domani corona...  0.552520  0.447480   \n",
      "3  mannoni raccomanda informarsi meglio coronavir...  0.291218  0.708782   \n",
      "4  coronavirus roma due turisti cinesi infetti po...  0.290802  0.709198   \n",
      "5  dovresti vedere trasmissione scoppierebbero im...  0.366130  0.633870   \n",
      "6  giuseppeconteit italiani stupidi fate politica...  0.046098  0.953902   \n",
      "7  detto voglio ricordare attualmente morti causa...  0.426675  0.573325   \n",
      "8                    gestione situazione coronavirus  0.334648  0.665352   \n",
      "9  lineanotte niente allarmismi salvo parlare uno...  0.024295  0.975705   \n",
      "\n",
      "   polarity  \n",
      "0  0.547295  \n",
      "1 -0.726255  \n",
      "2  0.105041  \n",
      "3 -0.417563  \n",
      "4 -0.418395  \n",
      "5 -0.267739  \n",
      "6 -0.907804  \n",
      "7 -0.146649  \n",
      "8 -0.330703  \n",
      "9 -0.951409  \n"
     ]
    }
   ],
   "source": [
    "# Quick glance at the dataframe\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most recurrent polarity:  0    0.154542\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Most recurrent polarity: \", df.polarity.mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving dataframe to csv\n",
    "df.to_csv('..\\\\Datasets\\\\CSV\\\\january_analyzed.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

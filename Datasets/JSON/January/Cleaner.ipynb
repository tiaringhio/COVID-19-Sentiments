{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading tweets from JSON file and ading them to Pandas Dataframe\n",
    "tweets = pd.read_json('saver_output.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting duplicate tweets\n",
    "tweets = tweets.drop_duplicates(subset='text')\n",
    "tweets['data'] = tweets['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining stopwords and adding a space before and after to exclude the case\n",
    "# in which the stopword is cointained in a word\n",
    "words = set(stopwords.words('italian'))\n",
    "stopwords = [' ' + x + ' ' for x in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the tags\n",
    "tweets.text = tweets.text.replace(\n",
    "    \"@[\\w]*[_-]*[\\w]*\", \" \", regex=True)\n",
    "# Removing the spaces in excess\n",
    "tweets.text = tweets.text.replace('\\s+', ' ', regex=True)\n",
    "# Removing the space at the beginning\n",
    "tweets.text = tweets.text.replace('^ ', '', regex=True)\n",
    "# Removing the space at the end\n",
    "tweets.text = tweets.text.replace(' $', '', regex=True)\n",
    "# To lowercase\n",
    "tweets.text = tweets.text.apply(\n",
    "    lambda x: x.lower())\n",
    "tweets.text = tweets.text.replace('^', ' ', regex=True)\n",
    "tweets.text = tweets.text.replace('$', ' ', regex=True)\n",
    "\n",
    "# Removing stopwords\n",
    "for word in stopwords:\n",
    "    tweets.text = tweets.text.replace(word, ' ', regex=True)\n",
    "\n",
    "# Removing the space at the beginning and at the end\n",
    "tweets.text = tweets.text.apply(lambda x: x.strip())\n",
    "# Removing empty tweets\n",
    "tweets = tweets[tweets.text != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to CSV\n",
    "tweets.to_csv('dataCleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
